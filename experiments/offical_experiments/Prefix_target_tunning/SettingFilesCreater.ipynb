{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f422d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_arguments_Prefix_MNLI_run1 import load_run_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d93bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "def SaveJsonFile(run_setting_files_output_folder,args,run_name):\n",
    "\n",
    "    print(f'{run_setting_files_output_folder}/{run_name}.json')\n",
    "    if os.path.isdir(run_setting_files_output_folder)==False:\n",
    "\n",
    "        os.mkdir(run_setting_files_output_folder)\n",
    "\n",
    "    with open(f'{run_setting_files_output_folder}/{run_name}.json', 'w') as outfile:\n",
    "        outfile.write(json.dumps(args,indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f491fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'stjokerli/TextToText_mnli_seqio', 'model_name_or_path': 'facebook/bart-large', 'cache_dir': '/workspace/w266_final_project/dataset_checkpoints/PETL_model', 'attn_mode': 'prefix', 'attn_option': 'concat', 'attn_composition': 'add', 'ffn_mode': 'none', 'ffn_option': 'parallel', 'ffn_adapter_layernorm_option': 'none', 'ffn_adapter_scalar': 4, 'ffn_adapter_init_option': 'lora', 'mid_dim': 800, 'attn_bn': 200, 'ffn_bn': 512, 'unfreeze_params': 'ef_', 'preprocessing_num_workers': 4, 'max_source_length': 512, 'max_target_length': 128, 'val_max_target_length': 10, 'max_eval_samples': 1500, 'num_beams': 5, 'max_length': 60, 'min_length': 1, 'no_repeat_ngram_size': 3, 'do_train': True, 'do_eval': True, 'do_predict': True, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 2, 'max_steps': 260000, 'num_train_epochs': 30, 'learning_rate': 5e-05, 'lr_scheduler_type': 'polynomial', 'max_grad_norm': 0.1, 'weight_decay': 0.01, 'warmup_steps': 0, 'fp16': True, 'logging_steps': 10, 'save_total_limit': 2, 'label_smoothing_factor': 0.1, 'evaluation_strategy': 'steps', 'save_strategy': 'steps', 'save_steps': 2500, 'eval_steps': 2500, 'load_best_model_at_end': True, 'report_to': 'wandb', 'run_name': 'MAM_MNLI_run1', 'overwrite_output_dir': True, 'disable_tqdm': True, 'metric_for_best_model': 'accuracy', 'greater_is_better': True, 'predict_with_generate': True, 'output_dir': '/workspace/w266_final_project/model_checkpoints/MAM_MNLI_run1'}\n"
     ]
    }
   ],
   "source": [
    "args=load_run_arguments()\n",
    "\n",
    "print(args)\n",
    "new_lr=args[\"learning_rate\"]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f667e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning//Source_tunning_settings.json\n"
     ]
    }
   ],
   "source": [
    "frame_work_name='Prefix'\n",
    "\n",
    "run_setting_files_output_folder_root=f'/workspace/w266_final_project/experiments/offical_experiments/{frame_work_name}_target_tunning/'\n",
    "\n",
    "check_point_location=f\"/workspace/w266_final_project/model_checkpoints/offical_experiments_checkpoints/{frame_work_name}_target_tunning/source_model/\"+\"checkpoint-222500\"\n",
    "\n",
    "SaveJsonFile(run_setting_files_output_folder_root,args,'Source_tunning_settings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e838cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_cb.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_rte.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_copa.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_wsc.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_wic.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_record.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_boolq.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_copa.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/bench_marks/Prefix_bench_marks_multirc.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_cb.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_rte.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_copa.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_wsc.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_wic.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_record.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_boolq.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_copa.json\n",
      "/workspace/w266_final_project/experiments/offical_experiments/Prefix_target_tunning/target_transfer_learnings/Prefix_target_transfer_learnings_multirc.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for base in ['bench_marks','target_transfer_learnings']:\n",
    "\n",
    "    for task_name in ['cb','rte','copa','wsc','wic','record','boolq','copa','multirc']:\n",
    "        \n",
    "        args[\"project\"]=\"Official_experiment\"\n",
    "        \n",
    "        args['dataset_name'] = f\"stjokerli/TextToText_{task_name}_seqio\"\n",
    "        args['run_name'] = run_name=f\"{frame_work_name}_{base}_{task_name}\"\n",
    "        args['output_dir'] = f\"/workspace/w266_final_project/model_checkpoints/offical_experiments_checkpoints/{frame_work_name}_target_tunning/{base}/{run_name}\" \n",
    "        \n",
    "        \n",
    "        args[\"max_eval_samples\"]= 1600\n",
    "        args[\"learning_rate\"]=new_lr\n",
    "        args[\"max_steps\"]= 100000\n",
    "        args['logging_steps']= 100\n",
    "        args['save_steps']=1500\n",
    "        args['eval_steps']=1500\n",
    "        \n",
    "        args['per_device_train_batch_size']= 16\n",
    "        args['per_device_eval_batch_size']= 16\n",
    "        args['gradient_accumulation_steps']= 2\n",
    "        \n",
    "        if base=='target_transfer_learnings':\n",
    "            \n",
    "            args[\"model_or_path\"]=check_point_location\n",
    "            args[\"load_path\"]=check_point_location\n",
    "            args[\"resume_from_checkpoint\"]=check_point_location\n",
    "            \n",
    "        SaveJsonFile(run_setting_files_output_folder_root+base,args,run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88675cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
